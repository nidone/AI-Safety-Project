---
layout: default
title: Home - AI Safety Project
---

# Evaluating LLM Safety for Youth: An AI Safety Course Project

In this project, I aim to evaluate the safety of large language models (LLMs), focusing specifically on their potential negative impacts on the emotional and cognitive development of youth. 

## Background

Over the past few decades, we’ve witnessed rapid technological advancements, some of which have unintentionally affected children and adolescents. A few notable examples include:

* Google and YouTube were [fined $170 million](https://www.ftc.gov/news-events/news/press-releases/2019/09/google-youtube-will-pay-record-170-million-alleged-violations-childrens-privacy-law) for violating children's privacy laws.
* The book [Anxious Generation](https://www.anxiousgeneration.com/book) highlights how smartphones and social networking services, especially Instagram, may have caused irreversible harm to adolescents.
* Oxford researchers have [raised concerns](https://www.ox.ac.uk/news/2024-03-21-ai-ethics-are-ignoring-children-say-oxford-researchers) that AI ethics discussions often overlook the impact on children.

Much of the research on AI safety to date has focused on issues like bias, disinformation, and fairness. However, there appears to be a significant gap when it comes to evaluating the effects of LLMs on youth development. As the competition among AI labs intensifies, there is a growing risk that the most vulnerable demographic—children and adolescents—may once again be negatively impacted.

This project is part of my final work for [the AI Safety Fundamentals: AI Alignment Course](https://aisafetyfundamentals.com/alignment/). I chose this topic because I believe it addresses an important, under-researched issue. Additionally, it allows me to apply some of the technical approaches I’ve learned during the course.

You can find more information about this project, including my GitHub repository and personal background, [here](https://github.com/nidone/AI-Safety-Project/) (currently private).

## Get Started

To begin exploring this project, start with the Methodology section, which outlines our approach.
