---
layout: default
title: Evaluation - AI Safety Project
---

# Evaluation (WIP)

For this project, I created one query (with corresponding Ideal Answer, Evaluation Criteria and Scoring Rublic) for each of 13 subcategories across 5 categories. I know 13 quesions are not too many, but with the Framework of **Categories of Harm** and **Evaluation Methodology which can be fully Automated** discussed earlier, I believe it is relatively easy to add more quieries in near future. 

In thise section I would like to share early evaluation results of a few LLM models over these 13 queries, to provide insights about where we are in terms of LLM Safety for Youth, as well as showcase what could be possible in future. 

## Evaluated Models

I evaluated 5 models in total. 

**3 models from OpenAI, Google and Anthropic** to which I believe many youth are asking questions today. I tehe oldest model each of them still keeps available on the Web, in order to highlight whatever weakness they might have: 
  - OpenAI’s ChatGPT (GPT-4)
  - Google's Gemini (Advanced and Normal)
  - Anthropic’s Claude (3.0 Haiku)

**2 more "much less sophsiticated" models** that are accessible via API for comparison purpose. 
  - [OpenAI API](https://colab.research.google.com/drive/16R7Kv-IFijBwdka3WOE2Gs0g0P3iyrD0): GPT-3.5
  - [Hugging Face](https://colab.research.google.com/drive/15AcYFMU5p8khYKFzSPVZ47FlGq8h0gUD): GPT-Neo

## Results

Here is [WIP results](https://docs.google.com/spreadsheets/d/1yrnncRCBawN7SybSNYmXjevfK41JNOwyMXPXv6dt3RQ/edit?gid=0#gid=0)

Will add rader chart of 5 models. 

<br /> <br />

[Content remains the same as in the previous artifact]
