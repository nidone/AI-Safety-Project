---
layout: default
title: Evaluation - AI Safety Project
---

# Evaluation (WIP)

For this project, I created one query for each of 13 subcategories across 5 harm categories. I know 13 queries are not enough as a dataset to ensure LLM safety for Youth, I woudld like to go through the end-to-end process and see what they can demonstrate about Youth-specific safety on some of widely-used LLMs today. In addition, as you have seen in the previous Methodology section, the framework is designed so that it is fairly easy to add more quieries later. 

Here are 13 queries I prepared, with corresponding Ideal Answer, Evaluation Criteria and Scoring Rublic. 

<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vSERmDJe-o35zSa4YW0_6ZlK1xSutyNS_HexLf1b7WMyDD33dm5guVuFC7Y7CKr_LDCoif5nwjq4h3N/pubhtml?gid=463039031&amp;single=true&amp;widget=true&amp;headers=false"
  style="width: 100%; height: 500px; border: none;">
</iframe>

## Evaluated Models

I evaluated 5 models in total. 

**3 models from OpenAI, Google and Anthropic** to which I believe many youth are asking questions today. I tehe oldest model each of them still keeps available on the Web, in order to highlight whatever weakness they might have: 
  - OpenAI’s ChatGPT (GPT-4)
  - Google's Gemini (Advanced and Normal)
  - Anthropic’s Claude (3.0 Haiku)

**2 more "much less sophsiticated" models** that are accessible via API for comparison purpose. 
  - [OpenAI API](https://colab.research.google.com/drive/16R7Kv-IFijBwdka3WOE2Gs0g0P3iyrD0): GPT-3.5
  - [Hugging Face](https://colab.research.google.com/drive/15AcYFMU5p8khYKFzSPVZ47FlGq8h0gUD): GPT-Neo

## Results


Here is [WIP results](https://docs.google.com/spreadsheets/d/1yrnncRCBawN7SybSNYmXjevfK41JNOwyMXPXv6dt3RQ/edit?gid=0#gid=0)

Will add rader chart of 5 models. 

<br /> <br />

[Content remains the same as in the previous artifact]
